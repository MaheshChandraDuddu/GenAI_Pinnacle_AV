{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a4548fa7fbf49adbe67112d4fc2d0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_574b0d476a3a445db6e8652dd01d13a3",
              "IPY_MODEL_1be11033ec2245d79a5b9134a0ed7fe1",
              "IPY_MODEL_8cee015217f04f4c8030c6d51d35e3d3"
            ],
            "layout": "IPY_MODEL_e9c16b65771245e8af71e1d71ecbaab1"
          }
        },
        "574b0d476a3a445db6e8652dd01d13a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a729d5116fb94937b2b8a81939e4a633",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_14d36b021a0242cca1536a588eb2bb2c",
            "value": "config.json:‚Äá100%"
          }
        },
        "1be11033ec2245d79a5b9134a0ed7fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b154926ed7954f80b87dd8f16644f8b3",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd2ef4dd37a8413e824fa96f5832240b",
            "value": 571
          }
        },
        "8cee015217f04f4c8030c6d51d35e3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_193bc4e09ce846e596a0b303164918e3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e95eb39293634328a70e572807e47fc3",
            "value": "‚Äá571/571‚Äá[00:00&lt;00:00,‚Äá12.4kB/s]"
          }
        },
        "e9c16b65771245e8af71e1d71ecbaab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a729d5116fb94937b2b8a81939e4a633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d36b021a0242cca1536a588eb2bb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b154926ed7954f80b87dd8f16644f8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2ef4dd37a8413e824fa96f5832240b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "193bc4e09ce846e596a0b303164918e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95eb39293634328a70e572807e47fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers trl accelerate torch bitsandbytes peft datasets -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o01F3H3zP3aG",
        "outputId": "fa184808-968e-45e1-e9b2-14e1fcc8454c",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:43:55.320748Z",
          "iopub.execute_input": "2024-08-12T11:43:55.321078Z",
          "iopub.status.idle": "2024-08-12T11:46:26.295718Z",
          "shell.execute_reply.started": "2024-08-12T11:43:55.321049Z",
          "shell.execute_reply": "2024-08-12T11:46:26.294765Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.4.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HF_TOKEN'] = \"--\""
      ],
      "metadata": {
        "id": "KFehPUXUITEr",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:26.297588Z",
          "iopub.execute_input": "2024-08-12T11:46:26.2979Z",
          "iopub.status.idle": "2024-08-12T11:46:26.302652Z",
          "shell.execute_reply.started": "2024-08-12T11:46:26.297872Z",
          "shell.execute_reply": "2024-08-12T11:46:26.301595Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "instruct_tune_dataset = load_dataset(\"FinGPT/fingpt-fiqa_qa\")\n",
        "instruct_tune_dataset\n",
        "\n",
        "type(instruct_tune_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a0ed34199295477dbe38ba03eb19d613",
            "e09fe11717614353a33a560999545a27",
            "4860866fd9e04dc3a0e133572294e3cc"
          ]
        },
        "id": "w5DK_ermQJin",
        "outputId": "4e123536-b667-4329-86bd-bf8d61cb6b6a",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:26.304139Z",
          "iopub.execute_input": "2024-08-12T11:46:26.304624Z",
          "iopub.status.idle": "2024-08-12T11:46:32.023635Z",
          "shell.execute_reply.started": "2024-08-12T11:46:26.304595Z",
          "shell.execute_reply": "2024-08-12T11:46:32.022752Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/522 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0ed34199295477dbe38ba03eb19d613"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/10.8M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e09fe11717614353a33a560999545a27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/17110 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4860866fd9e04dc3a0e133572294e3cc"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "datasets.dataset_dict.DatasetDict"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset[\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXCk7I6TSEo0",
        "outputId": "99c0c827-cb25-4c99-9063-09ee0b9971ee",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:32.026302Z",
          "iopub.execute_input": "2024-08-12T11:46:32.027311Z",
          "iopub.status.idle": "2024-08-12T11:46:32.032722Z",
          "shell.execute_reply.started": "2024-08-12T11:46:32.02728Z",
          "shell.execute_reply": "2024-08-12T11:46:32.03177Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 17110\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset[\"test\"] = instruct_tune_dataset[\"train\"].select(range(3000, 4500))\n",
        "instruct_tune_dataset[\"train\"] = instruct_tune_dataset[\"train\"].select(range(3000))"
      ],
      "metadata": {
        "id": "A37GeblkQ_I9",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:32.03389Z",
          "iopub.execute_input": "2024-08-12T11:46:32.034154Z",
          "iopub.status.idle": "2024-08-12T11:46:32.059954Z",
          "shell.execute_reply.started": "2024-08-12T11:46:32.034131Z",
          "shell.execute_reply": "2024-08-12T11:46:32.059123Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAGSndQMRJ9b",
        "outputId": "30f586c1-9373-461e-d870-762bc0f42b37",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:32.061056Z",
          "iopub.execute_input": "2024-08-12T11:46:32.061477Z",
          "iopub.status.idle": "2024-08-12T11:46:32.07268Z",
          "shell.execute_reply.started": "2024-08-12T11:46:32.061452Z",
          "shell.execute_reply": "2024-08-12T11:46:32.071846Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'input': 'What is considered a business expense on a business trip?',\n 'output': 'The IRS Guidance pertaining to the subject.  In general the best I can say is your business expense may be deductible.  But it depends on the circumstances and what it is you want to deduct. Travel Taxpayers who travel away from home on business may deduct related   expenses, including the cost of reaching their destination, the cost   of lodging and meals and other ordinary and necessary expenses.   Taxpayers are considered ‚Äútraveling away from home‚Äù if their duties   require them to be away from home substantially longer than an   ordinary day‚Äôs work and they need to sleep or rest to meet the demands   of their work. The actual cost of meals and incidental expenses may be   deducted or the taxpayer may use a standard meal allowance and reduced   record keeping requirements. Regardless of the method used, meal   deductions are generally limited to 50 percent as stated earlier.    Only actual costs for lodging may be claimed as an expense and   receipts must be kept for documentation. Expenses must be reasonable   and appropriate; deductions for extravagant expenses are not   allowable. More information is available in Publication 463, Travel,   Entertainment, Gift, and Car Expenses. Entertainment Expenses for entertaining clients, customers or employees may be   deducted if they are both ordinary and necessary and meet one of the   following tests: Directly-related test: The main purpose of the entertainment activity is the conduct of business, business was actually conducted   during the activity and the taxpayer had more than a general   expectation of getting income or some other specific business benefit   at some future time.   Associated test: The entertainment was associated with the active conduct of the taxpayer‚Äôs trade or business and occurred directly   before or after a substantial business discussion. Publication 463 provides more extensive explanation of these tests as   well as other limitations and requirements for deducting entertainment   expenses. Gifts Taxpayers may deduct some or all of the cost of gifts given in the   course of their trade or business. In general, the deduction is   limited to $25 for gifts given directly or indirectly to any one   person during the tax year. More discussion of the rules and   limitations can be found in Publication 463. If your LLC reimburses you for expenses outside of this guidance it should be treated as Income for tax purposes. Edit for Meal Expenses: Amount of standard meal allowance.   The standard meal allowance is   the federal M&IE rate. For travel in 2010, the rate for most small   localities in the United States is $46 a day. Source IRS P463 Alternately you could reimburse at a per diem rate',\n 'instruction': 'Utilize your financial knowledge, give your answer or opinion to the input question or subject . Answer format is not limited.'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset[\"test\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzg92Al2SaUX",
        "outputId": "3d90be6b-5218-469e-eb5f-e806e41dae83",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:32.073852Z",
          "iopub.execute_input": "2024-08-12T11:46:32.074612Z",
          "iopub.status.idle": "2024-08-12T11:46:32.082792Z",
          "shell.execute_reply.started": "2024-08-12T11:46:32.074588Z",
          "shell.execute_reply": "2024-08-12T11:46:32.081975Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'input': 'How much time would I have to spend trading to turn a profit?',\n 'output': 'What determines your profitability is not your time, but your TRADES. It is probably a mistake to go into the market and say, I hope to make X% today/this month/this year. As a practical matter, you can make a lot of money in a short period of time, or lose a lot over a long period of time (the latter is more likely). You\\'re better off looking at potential trades and saying \"I like this trade\" (be sure to know why) and \"I dislike that trade.\" If you\\'re right about your chosen trade, you\\'ll make money. Probably not on your original timetable, because markets react more slowly than individual people do. Then make ONLY those trades that you genuinely like and understand. IF you get into a \"rhythm,\" (rather few people do), your experience might tell you that you are likely to make, say, X% per month or year. But that\\'s ONLY if the market continues to accommodate YOUR style of trading. If the markets change, YOU must change (or get lost in the shuffle). Trading is a risky, if sometimes rewarding business. The operative motto here is: \"You pay your money and you take your chances,\" NOT \"You put in your time and eventually rewards will come.\"',\n 'instruction': 'Utilize your financial knowledge, give your answer or opinion to the input question or subject . Answer format is not limited.'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(sample):\n",
        "    bos_token = \"<s>\"\n",
        "    original_system_message = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    system_message = \"Use the provided input, response to generate the response with an LLM.\"\n",
        "    input = sample[\"input\"]\n",
        "    eos_token = \"</s>\"\n",
        "\n",
        "    full_prompt = \"\"\n",
        "    full_prompt += bos_token\n",
        "    full_prompt += \"\\n\" + original_system_message + \"\\n\" + system_message + \"\\n\"\n",
        "    full_prompt += \"### Instruction:\"\n",
        "    full_prompt += \"\\n\" + sample['instruction']\n",
        "    full_prompt += \"\\n\\n### Input:\"\n",
        "    full_prompt += \"\\n\" + sample['input']\n",
        "    full_prompt += \"\\n\\n### Response:\"\n",
        "    full_prompt += \"\\n\" + sample['output']\n",
        "    full_prompt += eos_token\n",
        "\n",
        "    return full_prompt"
      ],
      "metadata": {
        "id": "lVHOMQLCSntY",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:32.08386Z",
          "iopub.execute_input": "2024-08-12T11:46:32.084139Z",
          "iopub.status.idle": "2024-08-12T11:46:32.092388Z",
          "shell.execute_reply.started": "2024-08-12T11:46:32.084093Z",
          "shell.execute_reply": "2024-08-12T11:46:32.091545Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_prompt(instruct_tune_dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "gAnfQ3efS3vp",
        "outputId": "89356786-2dd8-4d82-eb2b-7c4b73244cd4",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:32.093523Z",
          "iopub.execute_input": "2024-08-12T11:46:32.093968Z",
          "iopub.status.idle": "2024-08-12T11:46:32.104353Z",
          "shell.execute_reply.started": "2024-08-12T11:46:32.093938Z",
          "shell.execute_reply": "2024-08-12T11:46:32.103492Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'<s>\\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\nUse the provided input, response to generate the response with an LLM.\\n### Instruction:\\nUtilize your financial knowledge, give your answer or opinion to the input question or subject . Answer format is not limited.\\n\\n### Input:\\nWhat is considered a business expense on a business trip?\\n\\n### Response:\\nThe IRS Guidance pertaining to the subject.  In general the best I can say is your business expense may be deductible.  But it depends on the circumstances and what it is you want to deduct. Travel Taxpayers who travel away from home on business may deduct related   expenses, including the cost of reaching their destination, the cost   of lodging and meals and other ordinary and necessary expenses.   Taxpayers are considered ‚Äútraveling away from home‚Äù if their duties   require them to be away from home substantially longer than an   ordinary day‚Äôs work and they need to sleep or rest to meet the demands   of their work. The actual cost of meals and incidental expenses may be   deducted or the taxpayer may use a standard meal allowance and reduced   record keeping requirements. Regardless of the method used, meal   deductions are generally limited to 50 percent as stated earlier.    Only actual costs for lodging may be claimed as an expense and   receipts must be kept for documentation. Expenses must be reasonable   and appropriate; deductions for extravagant expenses are not   allowable. More information is available in Publication 463, Travel,   Entertainment, Gift, and Car Expenses. Entertainment Expenses for entertaining clients, customers or employees may be   deducted if they are both ordinary and necessary and meet one of the   following tests: Directly-related test: The main purpose of the entertainment activity is the conduct of business, business was actually conducted   during the activity and the taxpayer had more than a general   expectation of getting income or some other specific business benefit   at some future time.   Associated test: The entertainment was associated with the active conduct of the taxpayer‚Äôs trade or business and occurred directly   before or after a substantial business discussion. Publication 463 provides more extensive explanation of these tests as   well as other limitations and requirements for deducting entertainment   expenses. Gifts Taxpayers may deduct some or all of the cost of gifts given in the   course of their trade or business. In general, the deduction is   limited to $25 for gifts given directly or indirectly to any one   person during the tax year. More discussion of the rules and   limitations can be found in Publication 463. If your LLC reimburses you for expenses outside of this guidance it should be treated as Income for tax purposes. Edit for Meal Expenses: Amount of standard meal allowance.   The standard meal allowance is   the federal M&IE rate. For travel in 2010, the rate for most small   localities in the United States is $46 a day. Source IRS P463 Alternately you could reimburse at a per diem rate</s>'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "-r-V2v8KXC5u",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:32.108188Z",
          "iopub.execute_input": "2024-08-12T11:46:32.108653Z",
          "iopub.status.idle": "2024-08-12T11:46:34.191951Z",
          "shell.execute_reply.started": "2024-08-12T11:46:32.108606Z",
          "shell.execute_reply": "2024-08-12T11:46:34.19077Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-2b-it\",\n",
        "    device_map='auto',\n",
        "    quantization_config=nf4_config,\n",
        "    use_cache=False\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "7a4548fa7fbf49adbe67112d4fc2d0eb",
            "574b0d476a3a445db6e8652dd01d13a3",
            "1be11033ec2245d79a5b9134a0ed7fe1",
            "8cee015217f04f4c8030c6d51d35e3d3",
            "e9c16b65771245e8af71e1d71ecbaab1",
            "a729d5116fb94937b2b8a81939e4a633",
            "14d36b021a0242cca1536a588eb2bb2c",
            "b154926ed7954f80b87dd8f16644f8b3",
            "dd2ef4dd37a8413e824fa96f5832240b",
            "193bc4e09ce846e596a0b303164918e3",
            "e95eb39293634328a70e572807e47fc3",
            "d43496e418f44609aa4c922f96fdb6d2",
            "228b6c0271524ab4b85a624f9b4c7bc2",
            "1585c50a61184725948e165a81cdb782",
            "726e25ecafc246a9abab5c5d988ea45e",
            "6a8e253af3ec4c8cae71d3d696ec777f",
            "8604da37e0fc41a69e8ef69227bc67d8",
            "4a59b46f8b674520916b43838406fbca",
            "d8b4a94cd7fc48d19e9cd69b95fd5f14",
            "6b2bf7e2f1fb4ed5b847e0ba75a7c313",
            "2d90b6f129304abbb7f1f3f0f91dc321",
            "47fa926f13d342cab0b64400c2a63056",
            "8b4b49421da241d39981bd9969074ebf"
          ]
        },
        "id": "zsjjwnfHXTNv",
        "outputId": "75fc8203-13bc-4488-a43e-8c7a31f9fa3a",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:46:34.193333Z",
          "iopub.execute_input": "2024-08-12T11:46:34.193964Z",
          "iopub.status.idle": "2024-08-12T11:47:03.73507Z",
          "shell.execute_reply.started": "2024-08-12T11:46:34.193926Z",
          "shell.execute_reply": "2024-08-12T11:47:03.734261Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "228b6c0271524ab4b85a624f9b4c7bc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1585c50a61184725948e165a81cdb782"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "726e25ecafc246a9abab5c5d988ea45e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a8e253af3ec4c8cae71d3d696ec777f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8604da37e0fc41a69e8ef69227bc67d8"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a59b46f8b674520916b43838406fbca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8b4a94cd7fc48d19e9cd69b95fd5f14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b2bf7e2f1fb4ed5b847e0ba75a7c313"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d90b6f129304abbb7f1f3f0f91dc321"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47fa926f13d342cab0b64400c2a63056"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b4b49421da241d39981bd9969074ebf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "1CpRPO7YX11r",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:47:03.736188Z",
          "iopub.execute_input": "2024-08-12T11:47:03.736759Z",
          "iopub.status.idle": "2024-08-12T11:47:17.159021Z",
          "shell.execute_reply.started": "2024-08-12T11:47:03.736705Z",
          "shell.execute_reply": "2024-08-12T11:47:17.158166Z"
        },
        "trusted": true,
        "outputId": "ac6b158c-6fa0-49bc-96b6-7def287556ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-08-12 11:47:05.893331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-12 11:47:05.893444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-12 11:47:06.018735: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "  output_dir = \"gemma_instruct_generation\",\n",
        "#   num_train_epochs=1,\n",
        "  max_steps = 50,\n",
        "  per_device_train_batch_size = 8,\n",
        "  warmup_steps = 3,\n",
        "  logging_steps=10,\n",
        "  save_strategy=\"epoch\",\n",
        "#   evaluation_strategy=\"epoch\",\n",
        "  evaluation_strategy=\"steps\",\n",
        "  eval_steps=10,\n",
        "  learning_rate=2e-4,\n",
        "  bf16=True,\n",
        "  lr_scheduler_type='constant',\n",
        ")"
      ],
      "metadata": {
        "id": "MBO136s8ITEv",
        "outputId": "cd8aed0b-495f-4ebc-f592-f8757249de9e",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:47:17.16021Z",
          "iopub.execute_input": "2024-08-12T11:47:17.161262Z",
          "iopub.status.idle": "2024-08-12T11:47:17.193354Z",
          "shell.execute_reply.started": "2024-08-12T11:47:17.161224Z",
          "shell.execute_reply": "2024-08-12T11:47:17.192439Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 256\n",
        "from trl import SFTConfig, SFTTrainer\n",
        "trainer = SFTTrainer(\n",
        "  model=model,\n",
        "  peft_config=peft_config,\n",
        "  max_seq_length=max_seq_length,\n",
        "  tokenizer=tokenizer,\n",
        "  packing=True,\n",
        "  formatting_func=create_prompt,\n",
        "  args=args,\n",
        "  train_dataset=instruct_tune_dataset[\"train\"],\n",
        "  eval_dataset=instruct_tune_dataset[\"test\"]\n",
        ")"
      ],
      "metadata": {
        "id": "_04kAWQvITEw",
        "outputId": "a4769352-25d3-47e6-f23b-561c40c90222",
        "colab": {
          "referenced_widgets": [
            "76b26bd6a22c401e9c34ff764f2c0c37",
            "b8277017cfde49f4b615a89820c3e0b3",
            "e0589532535a4f0fb6e183463ee6db41",
            "51e0f55bfc7345e28e2a93eb2740e3b1"
          ]
        },
        "execution": {
          "iopub.status.busy": "2024-08-12T11:47:17.194481Z",
          "iopub.execute_input": "2024-08-12T11:47:17.194776Z",
          "iopub.status.idle": "2024-08-12T11:47:22.18374Z",
          "shell.execute_reply.started": "2024-08-12T11:47:17.194749Z",
          "shell.execute_reply": "2024-08-12T11:47:22.182838Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:192: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0589532535a4f0fb6e183463ee6db41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51e0f55bfc7345e28e2a93eb2740e3b1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "max_steps is given, it will override any value given in num_train_epochs\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:432: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "trainer.train()\n",
        "print(time.time()- start)"
      ],
      "metadata": {
        "id": "8B72hFIqITEw",
        "outputId": "1c531e2d-659a-4a35-baa2-c278fe5b677c",
        "execution": {
          "iopub.status.busy": "2024-08-12T11:47:22.185482Z",
          "iopub.execute_input": "2024-08-12T11:47:22.185868Z",
          "iopub.status.idle": "2024-08-12T12:28:43.606621Z",
          "shell.execute_reply.started": "2024-08-12T11:47:22.185832Z",
          "shell.execute_reply": "2024-08-12T12:28:43.605317Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "wandb version 0.17.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.17.4"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240812_114734-kx85s2uh</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/duddumaheshchandra-analytics-vidhya/huggingface/runs/kx85s2uh' target=\"_blank\">gemma_instruct_generation</a></strong> to <a href='https://wandb.ai/duddumaheshchandra-analytics-vidhya/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/duddumaheshchandra-analytics-vidhya/huggingface' target=\"_blank\">https://wandb.ai/duddumaheshchandra-analytics-vidhya/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/duddumaheshchandra-analytics-vidhya/huggingface/runs/kx85s2uh' target=\"_blank\">https://wandb.ai/duddumaheshchandra-analytics-vidhya/huggingface/runs/kx85s2uh</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 40:45, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>4.991700</td>\n      <td>3.964801</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>3.652800</td>\n      <td>3.433610</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>3.249800</td>\n      <td>3.190021</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>3.124500</td>\n      <td>2.997518</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.897100</td>\n      <td>2.827067</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "2481.413826227188\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"gemma_instruct_generation\")"
      ],
      "metadata": {
        "id": "vMgBfgfyITEw",
        "execution": {
          "iopub.status.busy": "2024-08-12T12:28:43.608473Z",
          "iopub.execute_input": "2024-08-12T12:28:43.608839Z",
          "iopub.status.idle": "2024-08-12T12:28:44.557921Z",
          "shell.execute_reply.started": "2024-08-12T12:28:43.608808Z",
          "shell.execute_reply": "2024-08-12T12:28:44.556873Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, model):\n",
        "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
        "  model_inputs = encoded_input.to('cuda')\n",
        "\n",
        "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
        "\n",
        "  return decoded_output[0].replace(prompt, \"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T12:28:49.415983Z",
          "iopub.execute_input": "2024-08-12T12:28:49.416858Z",
          "iopub.status.idle": "2024-08-12T12:28:49.424704Z",
          "shell.execute_reply.started": "2024-08-12T12:28:49.41682Z",
          "shell.execute_reply": "2024-08-12T12:28:49.423736Z"
        },
        "trusted": true,
        "id": "MyFfY3a8l62n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruct_tune_dataset_1 = load_dataset(\"FinGPT/fingpt-fiqa_qa\")\n",
        "\n",
        "generate_response(create_prompt(instruct_tune_dataset_1['train'][6000]), model)"
      ],
      "metadata": {
        "id": "WSxXEFkFITEw",
        "outputId": "37464316-ee83-4e16-d157-f44b0b9f4d33",
        "execution": {
          "iopub.status.busy": "2024-08-12T12:28:50.46575Z",
          "iopub.execute_input": "2024-08-12T12:28:50.466116Z",
          "iopub.status.idle": "2024-08-12T12:28:53.126528Z",
          "shell.execute_reply.started": "2024-08-12T12:28:50.466087Z",
          "shell.execute_reply": "2024-08-12T12:28:53.125543Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'<bos>\\n\"How to Deal with Difficult Family In-Laws\" and \"Financial Independence Defined in Three Simple Steps\".<eos>'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity"
      ],
      "metadata": {
        "id": "AON8-rSQl62n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "def calculate_perplexity(model, tokenizer, text):\n",
        "    encodings = tokenizer(text, return_tensors='pt')\n",
        "    max_length = model.config.n_positions\n",
        "    stride = 512\n",
        "    lls = []\n",
        "\n",
        "    for i in range(0, encodings.input_ids.size(1), stride):\n",
        "        begin_loc = max(i + stride - max_length, 0)\n",
        "        end_loc = min(i + stride, encodings.input_ids.size(1))\n",
        "        trg_len = end_loc - i  # may be different from stride on last loop\n",
        "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(model.device)\n",
        "        target_ids = input_ids.clone()\n",
        "        target_ids[:, :-trg_len] = -100\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, labels=target_ids)\n",
        "            log_likelihood = outputs.loss * trg_len\n",
        "\n",
        "        lls.append(log_likelihood)\n",
        "\n",
        "    ppl = torch.exp(torch.stack(lls).sum() / end_loc)\n",
        "    return ppl.item()\n",
        "\n",
        "# Example usage:\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "text = create_prompt(instruct_tune_dataset_1['train'][6000])\n",
        "perplexity = calculate_perplexity(model, tokenizer, text)\n",
        "print(f\"Perplexity: {perplexity}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T12:31:27.168571Z",
          "iopub.execute_input": "2024-08-12T12:31:27.169455Z",
          "iopub.status.idle": "2024-08-12T12:31:31.843971Z",
          "shell.execute_reply.started": "2024-08-12T12:31:27.169418Z",
          "shell.execute_reply": "2024-08-12T12:31:31.843038Z"
        },
        "trusted": true,
        "id": "A9QLEfCdl62o",
        "outputId": "947d3afd-9fa5-4d1d-f009-f49aa2bf8c9a",
        "colab": {
          "referenced_widgets": [
            "2ca5a576923d4276ba6948bbcdd74cfe",
            "ee841d329f7c4721a6dd30ded9b69097",
            "8be9a1811cb6490280f059e7ec639cca",
            "c922ba5f4f9841eba0666ea6ce337b85",
            "1b8c93cd1d7548179d0d3a96b66498a3",
            "ee11d141b56e4b79a72a96dae3a7aa99",
            "685b6b997c5f49eeac7f2a4eeca2d739"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ca5a576923d4276ba6948bbcdd74cfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee841d329f7c4721a6dd30ded9b69097"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8be9a1811cb6490280f059e7ec639cca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c922ba5f4f9841eba0666ea6ce337b85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b8c93cd1d7548179d0d3a96b66498a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee11d141b56e4b79a72a96dae3a7aa99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "685b6b997c5f49eeac7f2a4eeca2d739"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Perplexity: 85.0977783203125\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_scores = []\n",
        "for qi in range(6000, 6050):\n",
        "    question = instruct_tune_dataset_1['train'][qi]\n",
        "    text = create_prompt(question)\n",
        "    perplexity = calculate_perplexity(model, tokenizer, text)\n",
        "    perplexity_scores += [perplexity]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T12:35:43.645527Z",
          "iopub.execute_input": "2024-08-12T12:35:43.645899Z",
          "iopub.status.idle": "2024-08-12T12:36:32.830784Z",
          "shell.execute_reply.started": "2024-08-12T12:35:43.645868Z",
          "shell.execute_reply": "2024-08-12T12:36:32.829507Z"
        },
        "trusted": true,
        "id": "PDhspr45l62o",
        "outputId": "7f458fe4-a07b-4ddd-a824-ba95fcc80347"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     perplexity \u001b[38;5;241m=\u001b[39m calculate_perplexity(model, tokenizer, text)\n\u001b[1;32m      6\u001b[0m     perplexity_scores \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [perplexity]\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Perplexity Score = \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mavg\u001b[49m(perplexity_scores))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'avg' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'avg' is not defined",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity Scores = \", perplexity_scores)\n",
        "print(\"Average Perplexity Score = \", sum(perplexity_scores)/len(perplexity_scores))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T12:37:28.522683Z",
          "iopub.execute_input": "2024-08-12T12:37:28.523727Z",
          "iopub.status.idle": "2024-08-12T12:37:28.530983Z",
          "shell.execute_reply.started": "2024-08-12T12:37:28.523661Z",
          "shell.execute_reply": "2024-08-12T12:37:28.529912Z"
        },
        "trusted": true,
        "id": "-Nzqht_pl62o",
        "outputId": "5aff451f-9929-4a44-b9ee-75399a5715ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Perplexity Scores =  [85.0977783203125, 39.03424835205078, 31.85991096496582, 46.065731048583984, 50.841651916503906, 36.39962387084961, 42.20903396606445, 54.20967483520508, 52.67879104614258, 30.671279907226562, 58.56127166748047, 52.64979553222656, 33.70178985595703, 25.746946334838867, 34.511863708496094, 38.29937744140625, 97.82427978515625, 24.773008346557617, 28.972036361694336, 59.04855728149414, 50.26161193847656, 35.8034553527832, 30.635177612304688, 32.95157241821289, 30.27048683166504, 25.227563858032227, 52.494537353515625, 48.4195671081543, 38.48335647583008, 24.0301513671875, 22.293746948242188, 41.56494903564453, 42.232177734375, 43.23939514160156, 45.46876907348633, 30.482315063476562, 40.90268325805664, 34.24925231933594, 24.274309158325195, 53.2537956237793, 41.27415466308594, 34.88194274902344, 77.32930755615234, 36.610389709472656, 46.761173248291016, 39.182315826416016, 34.78038787841797, 120.95513153076172, 75.3550033569336, 35.39178466796875]\nAverage Perplexity Score =  44.24434230804443\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cp2Ns3Tl62o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}